{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec0fc2c1",
   "metadata": {},
   "source": [
    "# Andres Graterol - 4031393 - Fall 22\n",
    "# Homework 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "faa55ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# TODO: DEBUG KERAS\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a75a7",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7b26439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weights \n",
    "number_of_classes_M = 2 \n",
    "number_of_features_F = 5\n",
    "# W is of size M x F (Each class (M) has 5 classes (F))\n",
    "\n",
    "# Initialize the weights from a uniform pdf with bounds [-1, 1]\n",
    "initial_weights = np.random.uniform(low=-1, high=1, \n",
    "                                   size=(number_of_classes_M, number_of_features_F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d66d5786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.93976513  0.10589197  0.0881246   0.88010835  0.3545333 ]\n",
      "[-0.93976513  0.10589197  0.0881246   0.88010835  0.3545333 ]\n"
     ]
    }
   ],
   "source": [
    "#print(initial_weights)\n",
    "\n",
    "# Number of data points \n",
    "N = 1000\n",
    "points_per_class = math.floor(N/2)\n",
    "\n",
    "# 1000 total training data points, 500 for each class\n",
    "training_data_points_class0 = np.random.normal(loc=0, scale=1, size=(points_per_class, number_of_features_F))\n",
    "training_data_points_class1 = np.random.normal(loc=0.1, scale=1, size=(points_per_class, number_of_features_F))\n",
    "\n",
    "# Combine the two classes into one array \n",
    "training_data_points_old = np.concatenate((training_data_points_class0, training_data_points_class1))\n",
    "\n",
    "# Make sure we keep track of indices to map the labels to\n",
    "enum = list(enumerate(training_data_points_old))\n",
    "random.shuffle(enum)\n",
    "indices, training_data_points = zip(*enum)\n",
    "\n",
    "training_data_points = np.array(training_data_points)\n",
    "\n",
    "# Making sure that the shuffling has worked correctly \n",
    "print(training_data_points[0])\n",
    "print(training_data_points_old[indices[0]])\n",
    "\n",
    "labels_class0 = []\n",
    "labels_class1 = []\n",
    "\n",
    "# Create one-hot encoding formatting\n",
    "for i in range(points_per_class):\n",
    "    labels_class0.append([1, 0])\n",
    "    labels_class1.append([0, 1])\n",
    "\n",
    "labels_class0 = np.array(labels_class0)\n",
    "labels_class1 = np.array(labels_class1)\n",
    "\n",
    "# Labels array will be of size (N, 2)\n",
    "labels = np.concatenate((labels_class0, labels_class1))\n",
    "\n",
    "#print(labels_class0)\n",
    "#print(labels_class1)\n",
    "\n",
    "lr = 0.00005 \n",
    "# Actually means 50 epochs (go through every 1000 points 50 times)\n",
    "# We get a 1000 new weights every iteration\n",
    "iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b84602d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute gradient matrix for each point\n",
    "def compute_gradient_matrix(point, label, output, number_of_classes, number_of_features):\n",
    "    matrix = np.zeros((number_of_classes, number_of_features))\n",
    "\n",
    "    for k in range(number_of_classes):\n",
    "        for i in range(number_of_features):\n",
    "            gradient = (output[k]-label[k])*point[i]\n",
    "            matrix[k, i] = gradient\n",
    "\n",
    "    return matrix\n",
    "\n",
    "# Function to add individual point's gradient matrices together per iteration\n",
    "def update_gradient_matrix(matrix1, matrix2):\n",
    "    final_matrix = np.zeros((2, 5))\n",
    "\n",
    "    for k in range(2):\n",
    "        for i in range(5):\n",
    "            final_matrix[k, i] = matrix1[k, i] + matrix2[k, i]\n",
    "\n",
    "    return final_matrix\n",
    "\n",
    "def map_to_class(prediction):\n",
    "    if (prediction[0] > prediction[1]):\n",
    "        # One-hot encoding for class 0\n",
    "        prediction = [1, 0]\n",
    "    else:\n",
    "        # One-hot encoding for class 1\n",
    "        prediction = [0, 1]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def compute_accuracy(prediction, label):    \n",
    "    if (prediction[0] == label[0]):\n",
    "        return 1\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec63aa5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m# Compute classification accuracy\u001b[39;00m\n\u001b[0;32m     25\u001b[0m prediction \u001b[39m=\u001b[39m map_to_class(output)\n\u001b[1;32m---> 26\u001b[0m correct_predictions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m compute_accuracy(prediction, labels[indices[j]])\n\u001b[0;32m     28\u001b[0m \u001b[39m#              (y1(x)     - tn1)^2\u001b[39;00m\n\u001b[0;32m     29\u001b[0m error_class0 \u001b[39m=\u001b[39m (output[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m labels[indices[j], \u001b[39m0\u001b[39m])\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "Cell \u001b[1;32mIn [39], line 31\u001b[0m, in \u001b[0;36mcompute_accuracy\u001b[1;34m(prediction, label)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_accuracy\u001b[39m(prediction, label):    \n\u001b[1;32m---> 31\u001b[0m     \u001b[39mif\u001b[39;00m (prediction[\u001b[39m0\u001b[39;49m] \u001b[39m==\u001b[39m label[\u001b[39m0\u001b[39m]):\n\u001b[0;32m     32\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Expecting 50 items in each of these \n",
    "accuracy_list = []\n",
    "error_list = []\n",
    "for i in range(iterations):\n",
    "    \n",
    "    # initialize a new gradient matrix to use for every iteration    \n",
    "    gradient_matrix = np.zeros((number_of_classes_M, number_of_features_F))    \n",
    "    iteration_error = 0\n",
    "    correct_predictions = 0\n",
    "    # Go through the 1000 data points every epoch\n",
    "    for j in range(N):\n",
    "\n",
    "        # If we are in the very first iteration, use the initial weights\n",
    "        if (i == 0):\n",
    "            # For some opbservation vector, x, of size F (number of features)\n",
    "            # output is given by y(x) = Wx = (y1(x), y2(x))^T\n",
    "            # Output is of size (2,) -> (2, 5) X (5,)\n",
    "\n",
    "            # GET THE OUTPUT FOR EVERY DATA POINT\n",
    "            output = np.matmul(initial_weights, training_data_points[j])\n",
    "        else:\n",
    "            output = np.matmul(updated_weights, training_data_points[j])\n",
    "\n",
    "        # Compute classification accuracy\n",
    "        prediction = map_to_class(output)\n",
    "        correct_predictions += compute_accuracy(prediction, labels[indices[j]])\n",
    "\n",
    "        #              (y1(x)     - tn1)^2\n",
    "        error_class0 = (output[0] - labels[indices[j], 0])**2\n",
    "        #              (y2(x)     - tn2)^2\n",
    "        error_class1 = (output[1] - labels[indices[j], 1])**2   \n",
    "        point_error = 0.5*error_class0 + 0.5*error_class1\n",
    "\n",
    "        iteration_error += point_error   \n",
    "        #error_list[i] = iteration_error\n",
    "\n",
    "        # Now compute the gradient matrix for the point...\n",
    "        point_matrix = compute_gradient_matrix(training_data_points[j], labels[indices[j]], output, number_of_classes_M, number_of_features_F)\n",
    "        gradient_matrix = update_gradient_matrix(gradient_matrix, point_matrix)\n",
    "\n",
    "    # Done with all the data points in an iteration\n",
    "    accuracy = correct_predictions/N\n",
    "    accuracy_list.append(accuracy)\n",
    "    error_list.append(iteration_error)\n",
    "\n",
    "    # New weights = weights from previous step - lr(gradients)\n",
    "    if (i == 0):\n",
    "        updated_weights = initial_weights - lr*(gradient_matrix)\n",
    "    else:\n",
    "        updated_weights = updated_weights - lr*(gradient_matrix)\n",
    "\n",
    "#print(error_list)\n",
    "x = np.linspace(0, iterations, 50)\n",
    "plt.scatter(x, error_list)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x, accuracy_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ff9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56f9367a",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961eab4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m number_of_units_in_hidden_layer \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39m#### load the BOSTON regression dataset\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39mboston_housing\u001b[39m.\u001b[39mload_data(path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mboston_housing.npz\u001b[39m\u001b[39m\"\u001b[39m, test_split\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m113\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39m#### pre-process the data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m x_train \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(x_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:62\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[1;32m---> 62\u001b[0m   module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()\n\u001b[0;32m     63\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, item)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:45\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[0;32m     48\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\models.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics \u001b[39mas\u001b[39;00m metrics_module\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m functional\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\metrics.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\activations.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m advanced_activations\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_object\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m serialize_keras_object\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\layers\\__init__.py:24\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m     21\u001b[0m \u001b[39m# Generic layers.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m InputLayer\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m InputSpec\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\input_layer.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m \u001b[39mimport\u001b[39;00m distributed_training_utils\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\base_layer.py:41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast_variable\n\u001b[1;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m loss_scale_optimizer\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m policy\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m layer_serialization\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\mixed_precision\\loss_scale_optimizer.py:1180\u001b[0m\n\u001b[0;32m   1175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer\u001b[39m.\u001b[39m_create_or_restore_slot_variable(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m         slot_variable_position, slot_name, variable)\n\u001b[0;32m   1179\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1180\u001b[0m mixed_precision\u001b[39m.\u001b[39;49m_register_wrapper_optimizer_cls(optimizer_v2\u001b[39m.\u001b[39mOptimizerV2,\n\u001b[0;32m   1181\u001b[0m                                                 LossScaleOptimizerV1)\n\u001b[0;32m   1184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_multiply_gradient\u001b[39m(gradient, scale):\n\u001b[0;32m   1185\u001b[0m   \u001b[39m\"\"\"Multiply a (possibly sparse) gradient by the given scale factor.\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls'"
     ]
    }
   ],
   "source": [
    "number_of_feature = 13\n",
    "number_of_units_in_hidden_layer = 100\n",
    "#### load the BOSTON regression dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(path=\"boston_housing.npz\", test_split=0.2, seed=113)\n",
    "#### pre-process the data\n",
    "x_train -= np.mean(x_train)\n",
    "x_train /= np.std(x_train)\n",
    "x_test -= np.mean(x_test)\n",
    "x_test /= np.std(x_test)\n",
    "\n",
    "NN_regression_model = tf.keras.Sequential()\n",
    "hidden_layer_1 = tf.keras.layers.Dense(units=number_of_units_in_hidden_layer, activation='relu') # define layer\n",
    "NN_regression_model.add(hidden_layer_1) # add layer\n",
    "hidden_layer_2 = tf.keras.layers.Dense(units=number_of_units_in_hidden_layer,\n",
    "    activation='relu') # define layer\n",
    "NN_regression_model.add(hidden_layer_2) # add layer\n",
    "output_layer = tf.keras.layers.Dense(units=1, activation=None) # define layer\n",
    "    #(units = 1 for regression)\n",
    "NN_regression_model.add(output_layer) # add layer\n",
    "\n",
    "\n",
    "NN_regression_model.fit(x_train, y_train, epochs=500, batch_size = 1)\n",
    "train_error_mse,_ = NN_regression_model.evaluate(x_train, y_train)\n",
    "test_error_mse ,_ = NN_regression_model.evaluate(x_test, y_test)\n",
    "print(\"MSE on training data = {} ; MSE of testing data ={}\".format(train_error_mse, test_error_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c501420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f2b8f7d7da3b55c8640ff0ad5b752ba61ffdffe564a4378c820bcd9964834b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
