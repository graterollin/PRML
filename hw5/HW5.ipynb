{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec0fc2c1",
   "metadata": {},
   "source": [
    "# Andres Graterol - 4031393 - Fall 22\n",
    "# Homework 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "faa55ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# TODO: DEBUG KERAS\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a75a7",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7b26439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weights \n",
    "number_of_classes_M = 2 \n",
    "number_of_features_F = 5\n",
    "# W is of size M x F (Each class (M) has 5 classes (F))\n",
    "\n",
    "# Initialize the weights from a uniform pdf with bounds [-1, 1]\n",
    "initial_weights = np.random.uniform(low=-1, high=1, \n",
    "                                   size=(number_of_classes_M, number_of_features_F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d66d5786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.93976513  0.10589197  0.0881246   0.88010835  0.3545333 ]\n",
      "[-0.93976513  0.10589197  0.0881246   0.88010835  0.3545333 ]\n"
     ]
    }
   ],
   "source": [
    "#print(initial_weights)\n",
    "\n",
    "# Number of data points \n",
    "N = 1000\n",
    "points_per_class = math.floor(N/2)\n",
    "\n",
    "# 1000 total training data points, 500 for each class\n",
    "training_data_points_class0 = np.random.normal(loc=0, scale=1, size=(points_per_class, number_of_features_F))\n",
    "training_data_points_class1 = np.random.normal(loc=0.1, scale=1, size=(points_per_class, number_of_features_F))\n",
    "\n",
    "# Combine the two classes into one array \n",
    "training_data_points_old = np.concatenate((training_data_points_class0, training_data_points_class1))\n",
    "\n",
    "# Make sure we keep track of indices to map the labels to\n",
    "enum = list(enumerate(training_data_points_old))\n",
    "random.shuffle(enum)\n",
    "indices, training_data_points = zip(*enum)\n",
    "\n",
    "training_data_points = np.array(training_data_points)\n",
    "\n",
    "# Making sure that the shuffling has worked correctly \n",
    "print(training_data_points[0])\n",
    "print(training_data_points_old[indices[0]])\n",
    "\n",
    "labels_class0 = []\n",
    "labels_class1 = []\n",
    "\n",
    "# Create one-hot encoding formatting\n",
    "for i in range(points_per_class):\n",
    "    labels_class0.append([1, 0])\n",
    "    labels_class1.append([0, 1])\n",
    "\n",
    "labels_class0 = np.array(labels_class0)\n",
    "labels_class1 = np.array(labels_class1)\n",
    "\n",
    "# Labels array will be of size (N, 2)\n",
    "labels = np.concatenate((labels_class0, labels_class1))\n",
    "\n",
    "#print(labels_class0)\n",
    "#print(labels_class1)\n",
    "\n",
    "lr = 0.00005 \n",
    "# Actually means 50 epochs (go through every 1000 points 50 times)\n",
    "# We get a 1000 new weights every iteration\n",
    "iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b84602d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute gradient matrix for each point\n",
    "def compute_gradient_matrix(point, label, output, number_of_classes, number_of_features):\n",
    "    matrix = np.zeros((number_of_classes, number_of_features))\n",
    "\n",
    "    for k in range(number_of_classes):\n",
    "        for i in range(number_of_features):\n",
    "            gradient = (output[k]-label[k])*point[i]\n",
    "            matrix[k, i] = gradient\n",
    "\n",
    "    return matrix\n",
    "\n",
    "# Function to add individual point's gradient matrices together per iteration\n",
    "def update_gradient_matrix(matrix1, matrix2):\n",
    "    final_matrix = np.zeros((2, 5))\n",
    "\n",
    "    for k in range(2):\n",
    "        for i in range(5):\n",
    "            final_matrix[k, i] = matrix1[k, i] + matrix2[k, i]\n",
    "\n",
    "    return final_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec63aa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1462.054731365862, 1365.8067678696966, 1279.0661412538266, 1200.8917701469586, 1130.435906646748, 1066.934863075943, 1009.7006616366378, 958.1135149707408, 911.6150548174425, 869.7022342232318, 831.9218361988586, 797.8655284131859, 767.1654095403914, 739.4899983015113, 714.5406211240677, 692.0481587385137, 671.7701159865119, 653.487982677231, 637.00485653355, 622.1433021558346, 608.7434225286798, 596.6611219345722, 585.766541243618, 575.9426484438123, 567.083968982388, 559.0954420250025, 551.8913901222846, 545.3945910184103, 539.5354414572646, 534.2512038509951, 529.4853275844284, 525.186837546954, 521.30978322015, 517.8127423126558, 514.6583735310774, 511.8130136134438, 509.24631423599436, 506.9309148400941, 504.8421478187494, 502.9577728557648, 501.25773752899954, 499.72396157592107, 498.34014247788355, 497.09158025211167, 495.96501954981653, 494.94850734745893, 494.03126468811917, 493.20357108284776, 492.4566603197434, 491.78262655258925]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ERROR IS PER ITERATION, SUM THE 1000 ERRORS FOR EACH ITERATION TO GET THE TOTAL ERROR FOR THAT STEP\n",
    "\n",
    "# New weights = weights from previous step - lr(gradients)\n",
    "\n",
    "\n",
    "# Want 50 by the end \n",
    "error_list = []\n",
    "for i in range(iterations):\n",
    "    \n",
    "    # initialize a new gradient matrix to use for every iteration    \n",
    "    gradient_matrix = np.zeros((number_of_classes_M, number_of_features_F))    \n",
    "    iteration_error = 0\n",
    "    # Go through the 1000 data points every epoch\n",
    "    for j in range(N):\n",
    "        \n",
    "\n",
    "        # If we are in the very first iteration, use the initial weights\n",
    "        if (i == 0):\n",
    "            # For some opbservation vector, x, of size F (number of features)\n",
    "            # output is given by y(x) = Wx = (y1(x), y2(x))^T\n",
    "            # Output is of size (2,) -> (2, 5) X (5,)\n",
    "\n",
    "            # GET THE OUTPUT FOR EVERY DATA POINT\n",
    "            output = np.matmul(initial_weights, training_data_points[j])\n",
    "        else:\n",
    "            output = np.matmul(updated_weights, training_data_points[j])\n",
    "\n",
    "        #              (y1(x)     - tn1)^2\n",
    "        error_class0 = (output[0] - labels[indices[j], 0])**2\n",
    "        #              (y2(x)     - tn2)^2\n",
    "        error_class1 = (output[1] - labels[indices[j], 1])**2   \n",
    "        point_error = 0.5*error_class0 + 0.5*error_class1\n",
    "\n",
    "        iteration_error += point_error   \n",
    "        #error_list[i] = iteration_error\n",
    "\n",
    "        # Now compute the gradient matrix for the point...\n",
    "        point_matrix = compute_gradient_matrix(training_data_points[j], labels[indices[j]], output, number_of_classes_M, number_of_features_F)\n",
    "        gradient_matrix = update_gradient_matrix(gradient_matrix, point_matrix)\n",
    "\n",
    "    error_list.append(iteration_error)\n",
    "\n",
    "    # Done with all the data points in an iteration\n",
    "    if (i == 0):\n",
    "        updated_weights = initial_weights - lr*(gradient_matrix)\n",
    "    else:\n",
    "        updated_weights = updated_weights - lr*(gradient_matrix)\n",
    "\n",
    "#print(error_list)\n",
    "x = np.linspace(0, iterations, 50)\n",
    "plt.scatter(x, error_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ff9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56f9367a",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961eab4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m number_of_units_in_hidden_layer \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39m#### load the BOSTON regression dataset\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39mboston_housing\u001b[39m.\u001b[39mload_data(path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mboston_housing.npz\u001b[39m\u001b[39m\"\u001b[39m, test_split\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m113\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39m#### pre-process the data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m x_train \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(x_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:62\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[1;32m---> 62\u001b[0m   module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()\n\u001b[0;32m     63\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, item)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:45\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[0;32m     48\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\models.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics \u001b[39mas\u001b[39;00m metrics_module\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m functional\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\metrics.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\activations.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m advanced_activations\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_object\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m serialize_keras_object\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\layers\\__init__.py:24\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m     21\u001b[0m \u001b[39m# Generic layers.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m InputLayer\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m InputSpec\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\input_layer.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m \u001b[39mimport\u001b[39;00m distributed_training_utils\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\base_layer.py:41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast_variable\n\u001b[1;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m loss_scale_optimizer\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m policy\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m layer_serialization\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\mixed_precision\\loss_scale_optimizer.py:1180\u001b[0m\n\u001b[0;32m   1175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer\u001b[39m.\u001b[39m_create_or_restore_slot_variable(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m         slot_variable_position, slot_name, variable)\n\u001b[0;32m   1179\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1180\u001b[0m mixed_precision\u001b[39m.\u001b[39;49m_register_wrapper_optimizer_cls(optimizer_v2\u001b[39m.\u001b[39mOptimizerV2,\n\u001b[0;32m   1181\u001b[0m                                                 LossScaleOptimizerV1)\n\u001b[0;32m   1184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_multiply_gradient\u001b[39m(gradient, scale):\n\u001b[0;32m   1185\u001b[0m   \u001b[39m\"\"\"Multiply a (possibly sparse) gradient by the given scale factor.\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls'"
     ]
    }
   ],
   "source": [
    "number_of_feature = 13\n",
    "number_of_units_in_hidden_layer = 100\n",
    "#### load the BOSTON regression dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(path=\"boston_housing.npz\", test_split=0.2, seed=113)\n",
    "#### pre-process the data\n",
    "x_train -= np.mean(x_train)\n",
    "x_train /= np.std(x_train)\n",
    "x_test -= np.mean(x_test)\n",
    "x_test /= np.std(x_test)\n",
    "\n",
    "NN_regression_model = tf.keras.Sequential()\n",
    "hidden_layer_1 = tf.keras.layers.Dense(units=number_of_units_in_hidden_layer, activation='relu') # define layer\n",
    "NN_regression_model.add(hidden_layer_1) # add layer\n",
    "hidden_layer_2 = tf.keras.layers.Dense(units=number_of_units_in_hidden_layer,\n",
    "    activation='relu') # define layer\n",
    "NN_regression_model.add(hidden_layer_2) # add layer\n",
    "output_layer = tf.keras.layers.Dense(units=1, activation=None) # define layer\n",
    "    #(units = 1 for regression)\n",
    "NN_regression_model.add(output_layer) # add layer\n",
    "\n",
    "\n",
    "NN_regression_model.fit(x_train, y_train, epochs=500, batch_size = 1)\n",
    "train_error_mse,_ = NN_regression_model.evaluate(x_train, y_train)\n",
    "test_error_mse ,_ = NN_regression_model.evaluate(x_test, y_test)\n",
    "print(\"MSE on training data = {} ; MSE of testing data ={}\".format(train_error_mse, test_error_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c501420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f2b8f7d7da3b55c8640ff0ad5b752ba61ffdffe564a4378c820bcd9964834b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
